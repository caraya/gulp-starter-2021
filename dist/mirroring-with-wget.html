<html lang="en" dir="ltr" class="no-js lazy">

<head>
  <!--<link rel="stylesheet" href="ccs/github.css">-->
  <link rel="stylesheet" href="css/normalize.css">
  <link rel="stylesheet" href="css/main.css">
  <link rel="stylesheet" href="css/image-load.css">
  <link rel="stylesheet" href="css/video-load.css">
  <link rel="stylesheet" href="css/prism.css">
  <!-- <script async src="scripts/menu.js"></script> -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title></title>
</head>

<body>
<article class="container">
  <h1 id="mirroring-a-site-using-wget">Mirroring a site using Wget</h1>
<p><a href="https://www.gnu.org/software/wget/">Wget</a> is the GNU/FSF alternative to <a href="https://curl.haxx.se/">CURL</a> used to retrieve files from the network via command line. Gettting a single file is easy but trying to get an entire directory it’s not so easy.</p>
<p>I’ve used a similar version to this command in the past but it turned into huge downloads that would take forever to complete.</p>
<p>I found this version in <a href="https://www.guyrutenberg.com/2014/05/02/make-offline-mirror-of-a-site-using-wget/">Guy Rutenberg’s site</a> and liked it after I used it to mirror a site.</p>
<p>The command is:</p>
<pre class="language-bash"><code class="language-bash"><span class="token function">wget</span> <span class="token parameter variable">--mirror</span> <span class="token punctuation">\</span>
--convert-links <span class="token punctuation">\</span>
--adjust-extension <span class="token punctuation">\</span>
--page-requisites
--no-parent http://example.org
</code></pre>
<p>These are flags we’re using:</p>
<ul>
<li>
<p><strong>–mirror</strong> – Mirrors a site by making the download recursive and enabling additional flags</p>
</li>
<li>
<p><strong>–convert-links</strong> – After the download is complete, convert the links in the document to make them suitable for local viewing. This affects not only the visible hyperlinks, but any part of the document that links to external content</p>
</li>
<li>
<p><strong>–adjust-extension</strong> – If a file of type <code>application/xhtml+xml</code> or <code>text/html</code> is downloaded and the URL does not end with the regexp <code>\.[Hh][Tt][Mm][Ll]?</code>, this option will cause the suffix ‘.html’ to be appended to the local filename.</p>
<p>This is useful, for instance, when you’re mirroring a remote site that uses ‘.asp’ pages, but you want the mirrored pages to be viewable on your stock Apache server</p>
</li>
<li>
<p><strong>–page-requisites</strong> – Download things like CSS style-sheets and images required to properly display the page offline.</p>
</li>
<li>
<p><strong>–no-parent</strong> – Do not go to the parent directory. It useful for restricting the download to only a portion of the site.</p>
</li>
</ul>
<p>Alternatively, the command above may be shortened:</p>
<pre class="language-bash"><code class="language-bash"><span class="token function">wget</span> <span class="token parameter variable">-mkEpnp</span> http://example.org
</code></pre>
<p>If the server’s robots.txt file is not configured to forbid it, you can run this command to mirror the specified directory and prepare it for offlline viewing by making some changes to the content and downloading all the needed materials to make the page viewable  offlline or in a different server.</p>

</article>
<!--
</div> -->
<script src="scripts/lazy-load.js"></script>
<script src="scripts/vendor/clipboard.min.js"></script>
<script src="scripts/vendor/prism.js"></script>
<script src="scripts/vendor/fontfaceobserver.js"></script>
<script src="scripts/load-fonts.js"></script>
<script src="scripts/lazy-load-video.js"></script>
</body>
</html>